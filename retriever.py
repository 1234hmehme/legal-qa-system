# retriever.py
# -*- coding: utf-8 -*-
"""
Retriever for Vietnamese Law QA System (Weaviate v4)
- Hybrid retrieval (BM25 + vector) on LawChunks
- Cross-Encoder reranking (BAAI/bge-reranker-v2-m3)
- Embed model: BAAI/bge-m3 (same as indexing)
- Rerank tr√™n: rerank_title + rerank_body (√≠t nhi·ªÖu, gi√†u ng·ªØ c·∫£nh)
"""

import os
import re
import torch
import weaviate
from sentence_transformers import SentenceTransformer, CrossEncoder

# ---------------- ENV SETUP ----------------
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'
torch.backends.mps.is_available = lambda: False  # type: ignore
torch.set_num_threads(1)

# ---------------- MODEL LOADING ----------------
print("üîπ Loading embedding model (BAAI/bge-m3)...")
emb_model = SentenceTransformer("BAAI/bge-m3", device="cpu")
print("‚úì Embedding model loaded on CPU")

print("üîπ Loading reranker model (BAAI/bge-reranker-v2-m3)...")
reranker = CrossEncoder("BAAI/bge-reranker-v2-m3", device="cpu")
print("‚úì Reranker model loaded on CPU")

# ---------------- WEAVIATE CONNECTION ----------------
print("üåê Connecting to Weaviate...")
client = weaviate.connect_to_local()
collection = client.collections.get("LawChunks")
print("‚úì Connected to collection: LawChunks")

# ---------------- UTILS ----------------
LEGAL_HINT_RE = re.compile(r"\b(Ch∆∞∆°ng|M·ª•c|ƒêi·ªÅu|Kho·∫£n|ƒêi·ªÉm)\b", re.IGNORECASE)
NUM_HINT_RE = re.compile(r"\b(\d{1,3})\b")

def tune_alpha_and_pool(query: str, base_alpha: float = 0.55, k: int = 5):
    """
    Heuristic:
      - N·∫øu query c√≥ ch·ªâ m·ª•c ph√°p l√Ω (Ch∆∞∆°ng/ƒêi·ªÅu/Kho·∫£n/ƒêi·ªÉm/s·ªë...), nghi√™ng BM25 h∆°n (alpha ‚Üì).
      - N·∫øu query mi√™u t·∫£ h√†nh vi b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n, nghi√™ng semantic h∆°n (alpha ‚Üë nh·∫π).
    """
    alpha = base_alpha
    initial_k = max(10, k * 5)

    if LEGAL_HINT_RE.search(query) or NUM_HINT_RE.search(query):
        alpha = max(0.35, base_alpha - 0.2)   # thi√™n BM25 h∆°n
        initial_k = max(15, k * 6)            # pool nhi·ªÅu h∆°n ƒë·ªÉ rerank
    else:
        alpha = min(0.7, base_alpha + 0.1)    # thi√™n semantic h∆°n

    return alpha, initial_k

# ---------------- RETRIEVAL FUNCTION ----------------
def retrieve(question: str, k: int = 5, base_alpha: float = 0.55):
    """
    Hybrid retrieval + Cross-Encoder reranking
    Returns: (context, sources)
    """
    print(f"\nüîç Retrieving for question: {question}")

    # Heuristic tune
    alpha, initial_k = tune_alpha_and_pool(question, base_alpha=base_alpha, k=k)
    print(f"   ‚ñ∂ alpha={alpha:.2f}, initial_k={initial_k}")

    # 1) Encode question ‚Üí dense vector (chu·∫©n v·ªõi indexing)
    qv = emb_model.encode([question], normalize_embeddings=True).astype("float32")

    # 2) Hybrid search (Weaviate v4): BM25 + vector
    #    L∆∞u √Ω: v4 kh√¥ng nh·∫≠n 'properties='; d√πng 'return_properties' ƒë·ªÉ l·∫•y fields c·∫ßn hi·ªÉn th·ªã/rerank.
    resp = collection.query.hybrid(
        query=question,
        vector=qv[0].tolist(),
        alpha=alpha,
        limit=initial_k,
        return_properties=[
            "law", "law_code", "header", "display_citation",
            "article_no", "clause_no", "point",
            "source_file", "path_text",
            "rerank_title", "rerank_body",
            "enriched_text",  # ‚úÖ text ƒë√£ c√≥ context kho·∫£n + m·ª©c ph·∫°t
            "text"  # backup/fallback
        ],
    )

    candidates = []
    for obj in resp.objects or []:
        p = obj.properties or {}
        # ∆Øu ti√™n rerank tr√™n rerank_title + rerank_body
        rr_title = (p.get("rerank_title") or "").strip()
        rr_body  = (p.get("rerank_body") or "").strip()
        if not rr_body and not rr_title:
            # fallback r·∫•t h·∫°n h·ªØu: d√πng text (leaf g·ªëc)
            rr_body = (p.get("text") or "").strip()
        rerank_text = (rr_title + "\n" + rr_body).strip()

        if not rerank_text:
            continue

        candidates.append({
            "rerank_text": rerank_text,
            "props": p
        })

    if not candidates:
        print("‚ö†Ô∏è No candidates found.")
        return "", []

    # 3) Cross-Encoder rerank
    print(f"üí° Reranking {len(candidates)} candidates...")
    pairs = [[question, c["rerank_text"]] for c in candidates]
    scores = reranker.predict(pairs)
    for i, c in enumerate(candidates):
        c["rerank_score"] = float(scores[i])

    topk = sorted(candidates, key=lambda x: x["rerank_score"], reverse=True)[:k]

    # 4) Compose context + sources (hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß v·ªõi enriched_text)
    contexts, sources = [], []
    for c in topk:
        p = c["props"]
        # ∆Øu ti√™n enriched_text (c√≥ context ƒë·∫ßy ƒë·ªß: chapter, article, clause_head)
        enriched = (p.get("enriched_text") or "").strip()
        if enriched:
            contexts.append(enriched)
        else:
            # Fallback: d√πng text g·ªëc
            header = p.get("header", "").strip()
            body = (p.get("text") or "").strip()
            if header and body:
                contexts.append(f"{header}: {body}")
            elif body:
                contexts.append(body)

        src = p.get("display_citation") or p.get("header", "") or ""
        law = p.get("law", "")
        sources.append(f"{law} ‚Äì {src}" if law else src)

    context = "\n\n".join(contexts)
    print(f"‚úÖ Retrieved {len(contexts)} top chunks")
    return context, sources

# ---------------- QUICK TEST ----------------
if __name__ == "__main__":
    try:
        q = "Theo lu·∫≠t m·ªõi, gi·∫•y ph√©p l√°i xe h·∫°ng A1 c·∫•p cho ng∆∞·ªùi l√°i xe m√¥ t√¥ hai b√°nh c√≥ dung t√≠ch xi-lanh ƒë·∫øn bao nhi√™u cm¬≥?"
        ctx, srcs = retrieve(q, k=5, base_alpha=0.55)
        print("\nüìò Full Context (all chunks):\n")
        print(ctx)  # In ƒë·∫ßy ƒë·ªß kh√¥ng truncate
        print("\nüìö Sources:")
        for s in srcs:
            print(" -", s)
    finally:
        client.close()
        print("\n‚úì Weaviate connection closed")
